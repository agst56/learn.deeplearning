{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0560af7b-db2f-416e-bb0b-d7295353e004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 3.5775\t\t  Epoch [1/50], Loss: 4.1247\n",
      "Epoch [2/50], Loss: 3.3575\t\t  Epoch [2/50], Loss: 3.2118\n",
      "Epoch [3/50], Loss: 2.9391\t\t  Epoch [3/50], Loss: 2.3076\n",
      "Epoch [4/50], Loss: 2.3615\t\t  Epoch [4/50], Loss: 1.0725\n",
      "Epoch [5/50], Loss: 1.6834\t\t  Epoch [5/50], Loss: 0.2672\n",
      "Epoch [6/50], Loss: 0.9105\t\t  Epoch [6/50], Loss: 0.0872\n",
      "Epoch [7/50], Loss: 0.4247\t\t  Epoch [7/50], Loss: 0.0474\n",
      "Epoch [8/50], Loss: 0.2073\t\t  Epoch [8/50], Loss: 0.0319\n",
      "Epoch [9/50], Loss: 0.1303\t\t  Epoch [9/50], Loss: 0.0236\n",
      "Epoch [10/50], Loss: 0.0853\t\t  Epoch [10/50], Loss: 0.0184\n",
      "Epoch [11/50], Loss: 0.0644\t\t  Epoch [11/50], Loss: 0.0149\n",
      "Epoch [12/50], Loss: 0.0508\t\t  Epoch [12/50], Loss: 0.0123\n",
      "Epoch [13/50], Loss: 0.0402\t\t  Epoch [13/50], Loss: 0.0104\n",
      "Epoch [14/50], Loss: 0.0331\t\t  Epoch [14/50], Loss: 0.0089\n",
      "Epoch [15/50], Loss: 0.0277\t\t  Epoch [15/50], Loss: 0.0077\n",
      "Epoch [16/50], Loss: 0.0240\t\t  Epoch [16/50], Loss: 0.0068\n",
      "Epoch [17/50], Loss: 0.0204\t\t  Epoch [17/50], Loss: 0.0060\n",
      "Epoch [18/50], Loss: 0.0179\t\t  Epoch [18/50], Loss: 0.0054\n",
      "Epoch [19/50], Loss: 0.0159\t\t  Epoch [19/50], Loss: 0.0048\n",
      "Epoch [20/50], Loss: 0.0141\t\t  Epoch [20/50], Loss: 0.0044\n",
      "Epoch [21/50], Loss: 0.0126\t\t  Epoch [21/50], Loss: 0.0040\n",
      "Epoch [22/50], Loss: 0.0114\t\t  Epoch [22/50], Loss: 0.0036\n",
      "Epoch [23/50], Loss: 0.0104\t\t  Epoch [23/50], Loss: 0.0033\n",
      "Epoch [24/50], Loss: 0.0094\t\t  Epoch [24/50], Loss: 0.0031\n",
      "Epoch [25/50], Loss: 0.0086\t\t  Epoch [25/50], Loss: 0.0028\n",
      "Epoch [26/50], Loss: 0.0079\t\t  Epoch [26/50], Loss: 0.0026\n",
      "Epoch [27/50], Loss: 0.0073\t\t  Epoch [27/50], Loss: 0.0024\n",
      "Epoch [28/50], Loss: 0.0067\t\t  Epoch [28/50], Loss: 0.0023\n",
      "Epoch [29/50], Loss: 0.0062\t\t  Epoch [29/50], Loss: 0.0021\n",
      "Epoch [30/50], Loss: 0.0058\t\t  Epoch [30/50], Loss: 0.0020\n",
      "Epoch [31/50], Loss: 0.0054\t\t  Epoch [31/50], Loss: 0.0019\n",
      "Epoch [32/50], Loss: 0.0050\t\t  Epoch [32/50], Loss: 0.0018\n",
      "Epoch [33/50], Loss: 0.0047\t\t  Epoch [33/50], Loss: 0.0017\n",
      "Epoch [34/50], Loss: 0.0044\t\t  Epoch [34/50], Loss: 0.0016\n",
      "Epoch [35/50], Loss: 0.0042\t\t  Epoch [35/50], Loss: 0.0015\n",
      "Epoch [36/50], Loss: 0.0039\t\t  Epoch [36/50], Loss: 0.0014\n",
      "Epoch [37/50], Loss: 0.0037\t\t  Epoch [37/50], Loss: 0.0013\n",
      "Epoch [38/50], Loss: 0.0035\t\t  Epoch [38/50], Loss: 0.0013\n",
      "Epoch [39/50], Loss: 0.0033\t\t  Epoch [39/50], Loss: 0.0012\n",
      "Epoch [40/50], Loss: 0.0031\t\t  Epoch [40/50], Loss: 0.0012\n",
      "Epoch [41/50], Loss: 0.0030\t\t  Epoch [41/50], Loss: 0.0011\n",
      "Epoch [42/50], Loss: 0.0028\t\t  Epoch [42/50], Loss: 0.0010\n",
      "Epoch [43/50], Loss: 0.0027\t\t  Epoch [43/50], Loss: 0.0010\n",
      "Epoch [44/50], Loss: 0.0026\t\t  Epoch [44/50], Loss: 0.0010\n",
      "Epoch [45/50], Loss: 0.0024\t\t  Epoch [45/50], Loss: 0.0009\n",
      "Epoch [46/50], Loss: 0.0023\t\t  Epoch [46/50], Loss: 0.0009\n",
      "Epoch [47/50], Loss: 0.0022\t\t  Epoch [47/50], Loss: 0.0008\n",
      "Epoch [48/50], Loss: 0.0021\t\t  Epoch [48/50], Loss: 0.0008\n",
      "Epoch [49/50], Loss: 0.0020\t\t  Epoch [49/50], Loss: 0.0008\n",
      "Epoch [50/50], Loss: 0.0019\t\t  Epoch [50/50], Loss: 0.0007\n",
      "The next character after g is h\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import string\n",
    "\n",
    "# 1. Prepare the dataset\n",
    "alphabet = string.ascii_lowercase\n",
    "char_to_idx = {char: idx for idx, char in enumerate(alphabet)}\n",
    "idx_to_char = {idx: char for idx, char in enumerate(alphabet)}\n",
    "\n",
    "# Create input and output pairs\n",
    "input_chars = alphabet[:-1]  # all letters except the last one\n",
    "output_chars = alphabet[1:]  # all letters except the first one\n",
    "\n",
    "# Convert to tensors\n",
    "input_indices = torch.tensor([char_to_idx[char] for char in input_chars])\n",
    "output_indices = torch.tensor([char_to_idx[char] for char in output_chars])\n",
    "\n",
    "# 2. Define the neural network\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):        \n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class SimpleNNWithFunction(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleNNWithFunction, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x * 5 #function 5x #might be better because it gives a hint that you gotta look afterward?\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Hyperparameters\n",
    "input_size = len(alphabet)\n",
    "hidden_size = 26\n",
    "output_size = len(alphabet)\n",
    "learning_rate = 0.01\n",
    "num_epochs = 50\n",
    "\n",
    "# 3. Initialize the neural network, loss function, and optimizer\n",
    "model = SimpleNN(input_size, hidden_size, output_size)\n",
    "modelF = SimpleNNWithFunction(input_size, hidden_size, output_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "optimizerF = optim.Adam(modelF.parameters(), lr=learning_rate)\n",
    "\n",
    "# 4. Train the neural network\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (input_idx, output_idx) in enumerate(zip(input_indices, output_indices)):\n",
    "        input_one_hot = torch.zeros(input_size)\n",
    "        input_one_hot[input_idx] = 1.0\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(input_one_hot.unsqueeze(0))\n",
    "        loss = criterion(outputs, output_idx.unsqueeze(0))\n",
    "\n",
    "        \n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        #modelF\n",
    "        outputsF = modelF(input_one_hot.unsqueeze(0))\n",
    "        lossF = criterion(outputsF, output_idx.unsqueeze(0))\n",
    "        optimizerF.zero_grad()\n",
    "        lossF.backward()\n",
    "        optimizerF.step()\n",
    "\n",
    "    #if (epoch+1) % 100 == 0:\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\\t\\t  Epoch [{epoch+1}/{num_epochs}], Loss: {lossF.item():.4f}')\n",
    "\n",
    "# 5. Test the neural network\n",
    "def predict_next_char(model, char):\n",
    "    model.eval()\n",
    "    input_idx = char_to_idx[char]\n",
    "    input_one_hot = torch.zeros(input_size)\n",
    "    input_one_hot[input_idx] = 1.0\n",
    "    with torch.no_grad():\n",
    "        output = model(input_one_hot.unsqueeze(0))\n",
    "        _, predicted_idx = torch.max(output, 1)\n",
    "    return idx_to_char[predicted_idx.item()]\n",
    "\n",
    "# Test the model\n",
    "test_char = 'g'\n",
    "predicted_char = predict_next_char(model, test_char)\n",
    "print(f'The next character after {test_char} is {predicted_char}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fc4dcc-e0ce-4f1b-b0ea-290b63e6cf20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
